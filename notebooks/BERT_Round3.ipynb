{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show similarity between reviews using the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x_train_df = pd.read_csv('../data_reviews/x_train.csv')\n",
    "x_test_df = pd.read_csv('../data_reviews/x_test.csv')\n",
    "y_train_df = pd.read_csv('../data_reviews/y_train.csv')\n",
    "\n",
    "save_dir = os.path.abspath('../data_reviews/')\n",
    "tr_embeddings_ND = np.load(os.path.join(save_dir, 'x_train_BERT_embeddings.npy'))\n",
    "te_embeddings_ND = np.load(os.path.join(save_dir, 'x_test_BERT_embeddings.npy'))\n",
    "\n",
    "# from sklearn.preprocessing import normalize\n",
    "# tr_embeddings_ND = normalize(tr_embeddings_ND)\n",
    "# te_embeddings_ND = normalize(te_embeddings_ND)\n",
    "\n",
    "\n",
    "tr_text_list = x_train_df['text'].values.tolist()\n",
    "te_text_list = x_test_df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "SEED = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(tr_embeddings_ND, y_train_df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ON TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8493055555555555, 0.8502690972222222, 0.8337934027777779, 0.8728385416666666, 0.8546701388888889]\n",
      "[0.8810677083333334, 0.9069010416666667, 0.9051909722222222, 0.9031944444444444, 0.8859635416666667]\n",
      "[0.89625, 0.9113194444444445, 0.9148697916666667, 0.9144965277777779, 0.9008246527777777]\n",
      "[0.9078298611111112, 0.9272048611111111, 0.9167361111111112, 0.9196701388888888, 0.9114930555555555]\n",
      "[0.9095833333333333, 0.929123263888889, 0.9119965277777778, 0.9251562499999999, 0.9161631944444444]\n",
      "[0.9143402777777778, 0.9303385416666666, 0.9097743055555555, 0.9312152777777777, 0.9183854166666666]\n",
      "[0.9127430555555556, 0.935625, 0.9121875000000002, 0.9341493055555555, 0.9160243055555556]\n",
      "[0.9178993055555555, 0.9330555555555555, 0.9163194444444445, 0.9350173611111112, 0.9157812500000001]\n",
      "[0.9204340277777777, 0.9343055555555555, 0.9171180555555556, 0.9320312499999999, 0.9168402777777778]\n",
      "[0.9225520833333334, 0.9361979166666666, 0.9174131944444444, 0.9333506944444444, 0.9188194444444445]\n",
      "[0.9228472222222224, 0.9332465277777777, 0.9154340277777779, 0.9367534722222222, 0.9190104166666666]\n",
      "[0.9249131944444443, 0.9335590277777779, 0.9169791666666667, 0.9378819444444445, 0.9177256944444443]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Get predictions for training and validation sets\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m y_train_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     29\u001b[0m y_val_pred_proba \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate AUROC for each fold\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:286\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    284\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     neigh_dist, neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    289\u001b[0m _y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/neighbors/_base.py:824\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    817\u001b[0m use_pairwise_distances_reductions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ArgKmin\u001b[38;5;241m.\u001b[39mis_usable_for(\n\u001b[1;32m    820\u001b[0m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_\n\u001b[1;32m    821\u001b[0m     )\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[0;32m--> 824\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mArgKmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecomputed\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[1;32m    836\u001b[0m ):\n\u001b[1;32m    837\u001b[0m     results \u001b[38;5;241m=\u001b[39m _kneighbors_from_graph(\n\u001b[1;32m    838\u001b[0m         X, n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors, return_distance\u001b[38;5;241m=\u001b[39mreturn_distance\n\u001b[1;32m    839\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:289\u001b[0m, in \u001b[0;36mArgKmin.compute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArgKmin64\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[1;32m    278\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    279\u001b[0m         Y\u001b[38;5;241m=\u001b[39mY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m         return_distance\u001b[38;5;241m=\u001b[39mreturn_distance,\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mArgKmin32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly float64 or float32 datasets pairs are supported at this time, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot: X.dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Y.dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m )\n",
      "File \u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx:584\u001b[0m, in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/micromamba/envs/cs135_env/lib/python3.10/site-packages/threadpoolctl.py:592\u001b[0m, in \u001b[0;36m_ThreadpoolLimiter.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_original_limits()\n\u001b[1;32m    595\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m, controller, \u001b[38;5;241m*\u001b[39m, limits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, user_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the KFold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "neighbors = np.linspace(2, 150, dtype=int)\n",
    "results = np.empty(neighbors.shape)\n",
    "\n",
    "train_auroc_means = []\n",
    "val_auroc_means = []\n",
    "train_auroc_std = []\n",
    "val_auroc_std = []\n",
    "\n",
    "# Perform cross-validation for each choice of neighbors\n",
    "for i, neighbor in enumerate(neighbors): \n",
    "    train_auroc_per_fold = []\n",
    "    val_auroc_per_fold = []\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor, weights='distance')\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(tr_embeddings_ND, y_train_df.values.ravel()):\n",
    "        # Split data into training and validation sets\n",
    "        X_train, X_val = tr_embeddings_ND[train_idx], tr_embeddings_ND[val_idx]\n",
    "        y_train, y_val = y_train_df.values.ravel()[train_idx], y_train_df.values.ravel()[val_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predictions for training and validation sets\n",
    "        y_train_pred_proba = knn.predict_proba(X_train)[:, 1]\n",
    "        y_val_pred_proba = knn.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Calculate AUROC for each fold\n",
    "        train_auroc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "        val_auroc = roc_auc_score(y_val, y_val_pred_proba)\n",
    "        \n",
    "        train_auroc_per_fold.append(train_auroc)\n",
    "        val_auroc_per_fold.append(val_auroc)\n",
    "    \n",
    "    # Calculate the mean and standard deviation of AUROC scores across folds\n",
    "    train_auroc_means.append(np.mean(train_auroc_per_fold))\n",
    "    val_auroc_means.append(np.mean(val_auroc_per_fold))\n",
    "    train_auroc_std.append(np.std(train_auroc_per_fold))\n",
    "    val_auroc_std.append(np.std(val_auroc_per_fold))\n",
    "    \n",
    "    # Store the cross-validation score for selecting the best neighbors\n",
    "    yhat_cv_pred = cross_val_predict(knn, tr_embeddings_ND, y_train_df.values.ravel(),\n",
    "                                     cv=cv, method='predict_proba')\n",
    "    score = roc_auc_score(y_train_df, yhat_cv_pred[:, 1])  # Probability for class 1\n",
    "    results[i] = score\n",
    "\n",
    "# Find the best number of neighbors\n",
    "best_neighbors_idx = np.argmax(results)\n",
    "best_neighbors = neighbors[best_neighbors_idx]\n",
    "\n",
    "print(f\"Best AUROC score: {results[best_neighbors_idx]}\")\n",
    "print(f\"Optimal number of neighbors: {best_neighbors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132696759259259\n"
     ]
    }
   ],
   "source": [
    "mean_train_score = np.mean(train_auroc_means)\n",
    "mean_val_score = np.mean(val_auroc_means)\n",
    "\n",
    "# std_train_score = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP data:\n",
      "FP indices chosen: [0, 8, 17, 23, 24, 25, 26, 38, 40, 46]\n",
      "FP predictions and true sentiments [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]\n",
      "Sentences that were FP: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_05a67_row0_col0, #T_05a67_row0_col1, #T_05a67_row1_col0, #T_05a67_row1_col1, #T_05a67_row2_col0, #T_05a67_row2_col1, #T_05a67_row3_col0, #T_05a67_row3_col1, #T_05a67_row4_col0, #T_05a67_row4_col1, #T_05a67_row5_col0, #T_05a67_row5_col1, #T_05a67_row6_col0, #T_05a67_row6_col1, #T_05a67_row7_col0, #T_05a67_row7_col1, #T_05a67_row8_col0, #T_05a67_row8_col1, #T_05a67_row9_col0, #T_05a67_row9_col1 {\n",
       "  text_align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_05a67\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_05a67_level0_col0\" class=\"col_heading level0 col0\" >website_name</th>\n",
       "      <th id=\"T_05a67_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_05a67_row0_col0\" class=\"data row0 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row0_col1\" class=\"data row0 col1\" >Oh and I forgot to also mention the weird color effect it has on your phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row1\" class=\"row_heading level0 row1\" >8</th>\n",
       "      <td id=\"T_05a67_row1_col0\" class=\"data row1 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row1_col1\" class=\"data row1 col1\" >the only VERY DISAPPOINTING thing was there was NO SPEAKERPHONE!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row2\" class=\"row_heading level0 row2\" >17</th>\n",
       "      <td id=\"T_05a67_row2_col0\" class=\"data row2 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row2_col1\" class=\"data row2 col1\" >I advise EVERYONE DO NOT BE FOOLED!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row3\" class=\"row_heading level0 row3\" >23</th>\n",
       "      <td id=\"T_05a67_row3_col0\" class=\"data row3 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row3_col1\" class=\"data row3 col1\" >We have tried 2 units and they both failed within 2 months.. Pros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row4\" class=\"row_heading level0 row4\" >24</th>\n",
       "      <td id=\"T_05a67_row4_col0\" class=\"data row4 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row4_col1\" class=\"data row4 col1\" >Also difficult to put on.I'd recommend avoiding this product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row5\" class=\"row_heading level0 row5\" >25</th>\n",
       "      <td id=\"T_05a67_row5_col0\" class=\"data row5 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row5_col1\" class=\"data row5 col1\" >$50 Down the drain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row6\" class=\"row_heading level0 row6\" >26</th>\n",
       "      <td id=\"T_05a67_row6_col0\" class=\"data row6 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row6_col1\" class=\"data row6 col1\" >Absolutel junk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row7\" class=\"row_heading level0 row7\" >38</th>\n",
       "      <td id=\"T_05a67_row7_col0\" class=\"data row7 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row7_col1\" class=\"data row7 col1\" >[...] down the drain because of a weak snap!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row8\" class=\"row_heading level0 row8\" >40</th>\n",
       "      <td id=\"T_05a67_row8_col0\" class=\"data row8 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row8_col1\" class=\"data row8 col1\" >Pretty piece of junk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05a67_level0_row9\" class=\"row_heading level0 row9\" >46</th>\n",
       "      <td id=\"T_05a67_row9_col0\" class=\"data row9 col0\" >amazon</td>\n",
       "      <td id=\"T_05a67_row9_col1\" class=\"data row9 col1\" >If you are looking for a good quality Motorola Headset keep looking, this isn't it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a85f5ae0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_neighbors, weights='distance')\n",
    "yhat_cv_pred = cross_val_predict(knn, tr_embeddings_ND, y_train_df.values.ravel(), \n",
    "                                     cv=cv, method='predict_proba')\n",
    "yhat_pred = list()\n",
    "for value in yhat_cv_pred[:, 1]:\n",
    "    if value < 0.5:\n",
    "        yhat_pred.append(0)\n",
    "    else:\n",
    "        yhat_pred.append(1)\n",
    "\n",
    "y_train_values = y_train_df.values.ravel()  # Flatten y_train_df to a 1D array if necessary\n",
    "yhat_pred = np.array(yhat_pred)\n",
    "\n",
    "_, fp, fn, _ = confusion_matrix(y_train_values, yhat_pred).ravel()\n",
    "FP = []\n",
    "FN = []\n",
    "\n",
    "\n",
    "for i, pred in enumerate(yhat_pred):\n",
    "    if pred == 1 and y_train_values[i] == 0:\n",
    "        FP.append(i)\n",
    "    if pred == 0 and y_train_values[i] == 1:\n",
    "        FN.append(i)\n",
    "\n",
    "# print(FP)\n",
    "\n",
    "# print(x_va.iloc[FP[0]])\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option(\"display.colheader_justify\",\"left\")\n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "\n",
    "va_idx_FP = FP[0:10]\n",
    "va_sent_predict_FP = yhat_pred[va_idx_FP]\n",
    "va_sent_true_FP = y_train_values[va_idx_FP]\n",
    "FP_styled_df = x_train_df.iloc[va_idx_FP].style.set_properties(**{'text_align': 'right'})\n",
    "\n",
    "print(\"FP data:\")\n",
    "print(\"FP indices chosen:\", va_idx_FP)\n",
    "print(\"FP predictions and true sentiments\", va_sent_predict_FP, va_sent_true_FP)\n",
    "print(\"Sentences that were FP: \\n\")\n",
    "FP_styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN data:\n",
      "FN indices chosen: [412, 430, 435, 444, 453, 455, 458, 461, 482, 487]\n",
      "FN predictions and true sentiments [0 0 0 0 0 0 0 0 0 0] [1 1 1 1 1 1 1 1 1 1]\n",
      "Sentences that were FN: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9af5a_row0_col0, #T_9af5a_row0_col1, #T_9af5a_row1_col0, #T_9af5a_row1_col1, #T_9af5a_row2_col0, #T_9af5a_row2_col1, #T_9af5a_row3_col0, #T_9af5a_row3_col1, #T_9af5a_row4_col0, #T_9af5a_row4_col1, #T_9af5a_row5_col0, #T_9af5a_row5_col1, #T_9af5a_row6_col0, #T_9af5a_row6_col1, #T_9af5a_row7_col0, #T_9af5a_row7_col1, #T_9af5a_row8_col0, #T_9af5a_row8_col1, #T_9af5a_row9_col0, #T_9af5a_row9_col1 {\n",
       "  text_align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9af5a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9af5a_level0_col0\" class=\"col_heading level0 col0\" >website_name</th>\n",
       "      <th id=\"T_9af5a_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row0\" class=\"row_heading level0 row0\" >412</th>\n",
       "      <td id=\"T_9af5a_row0_col0\" class=\"data row0 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row0_col1\" class=\"data row0 col1\" >Plan on ordering from them again and again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row1\" class=\"row_heading level0 row1\" >430</th>\n",
       "      <td id=\"T_9af5a_row1_col0\" class=\"data row1 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row1_col1\" class=\"data row1 col1\" >I have to use the smallest earpieces provided, but it stays on pretty well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row2\" class=\"row_heading level0 row2\" >435</th>\n",
       "      <td id=\"T_9af5a_row2_col0\" class=\"data row2 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row2_col1\" class=\"data row2 col1\" >This is cool because most cases are just open there allowing the screen to get all scratched up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row3\" class=\"row_heading level0 row3\" >444</th>\n",
       "      <td id=\"T_9af5a_row3_col0\" class=\"data row3 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row3_col1\" class=\"data row3 col1\" >I was amazed at the quick arrival of the two original lg cell phone batteries and and at a fraction of the price.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row4\" class=\"row_heading level0 row4\" >453</th>\n",
       "      <td id=\"T_9af5a_row4_col0\" class=\"data row4 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row4_col1\" class=\"data row4 col1\" >Overall, I would recommend this phone over the new Walkman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row5\" class=\"row_heading level0 row5\" >455</th>\n",
       "      <td id=\"T_9af5a_row5_col0\" class=\"data row5 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row5_col1\" class=\"data row5 col1\" >I ended up sliding it on the edge of my pants or back pockets instead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row6\" class=\"row_heading level0 row6\" >458</th>\n",
       "      <td id=\"T_9af5a_row6_col0\" class=\"data row6 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row6_col1\" class=\"data row6 col1\" >I had to go to a store and bought a new NOKIA phone which is working great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row7\" class=\"row_heading level0 row7\" >461</th>\n",
       "      <td id=\"T_9af5a_row7_col0\" class=\"data row7 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row7_col1\" class=\"data row7 col1\" >It seems completely secure, both holding on to my belt, and keeping the iPhone inside.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row8\" class=\"row_heading level0 row8\" >482</th>\n",
       "      <td id=\"T_9af5a_row8_col0\" class=\"data row8 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row8_col1\" class=\"data row8 col1\" >This is hands down the best phone I've ever had.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9af5a_level0_row9\" class=\"row_heading level0 row9\" >487</th>\n",
       "      <td id=\"T_9af5a_row9_col0\" class=\"data row9 col0\" >amazon</td>\n",
       "      <td id=\"T_9af5a_row9_col1\" class=\"data row9 col1\" >It definitely was not as good as my S11.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x299a91450>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_idx_FN = FN[0:10]\n",
    "va_sent_predict_FN = yhat_pred[va_idx_FN]\n",
    "va_sent_true_FN = y_train_values[va_idx_FN]\n",
    "FN_styled_df = x_train_df.iloc[va_idx_FN].style.set_properties(**{'text_align': 'right'})\n",
    "\n",
    "print(\"FN data:\")\n",
    "print(\"FN indices chosen:\", va_idx_FN)\n",
    "print(\"FN predictions and true sentiments\", va_sent_predict_FN, va_sent_true_FN)\n",
    "print(\"Sentences that were FN: \\n\")\n",
    "FN_styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose some query sentences\n",
    "\n",
    "# use K-nearest neighbors to find the 5 reviews that most closely resemble the query review\n",
    "# for test_id in range(len(x_train)):\n",
    "#     query_QF = tr_embeddings_ND[test_id][np.newaxis, :]\n",
    "knn = KNeighborsClassifier(best_neighbors, weights='distance')\n",
    "knn.fit(tr_embeddings_ND, y_train_df.values.ravel())\n",
    "\n",
    "yhat = knn.predict_proba(te_embeddings_ND)\n",
    "\n",
    "file = open(\"yproba1_test.txt\", \"w+\")\n",
    "for value in yhat[:, 1]:\n",
    "    line = str(value) + \"\\n\"\n",
    "    file.write(line)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
