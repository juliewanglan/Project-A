{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show similarity between reviews using the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x_train_df = pd.read_csv('../data_reviews/x_train.csv')\n",
    "x_test_df = pd.read_csv('../data_reviews/x_test.csv')\n",
    "y_train_df = pd.read_csv('../data_reviews/y_train.csv')\n",
    "\n",
    "save_dir = os.path.abspath('../data_reviews/')\n",
    "tr_embeddings_ND = np.load(os.path.join(save_dir, 'x_train_BERT_embeddings.npy'))\n",
    "te_embeddings_ND = np.load(os.path.join(save_dir, 'x_test_BERT_embeddings.npy'))\n",
    "\n",
    "# from sklearn.preprocessing import normalize\n",
    "# tr_embeddings_ND = normalize(tr_embeddings_ND)\n",
    "# te_embeddings_ND = normalize(te_embeddings_ND)\n",
    "\n",
    "\n",
    "tr_text_list = x_train_df['text'].values.tolist()\n",
    "te_text_list = x_test_df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "SEED = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(tr_embeddings_ND, y_train_df, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ON TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KFold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "neighbors = np.linspace(2, 150, dtype=int)\n",
    "results = np.empty(neighbors.shape)\n",
    "\n",
    "train_auroc_means = []\n",
    "val_auroc_means = []\n",
    "train_auroc_std = []\n",
    "val_auroc_std = []\n",
    "\n",
    "# Perform cross-validation for each choice of neighbors\n",
    "for i, neighbor in enumerate(neighbors): \n",
    "    train_auroc_per_fold = []\n",
    "    val_auroc_per_fold = []\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor, weights='distance')\n",
    "    \n",
    "    for train_idx, val_idx in cv.split(tr_embeddings_ND, y_train_df.values.ravel()):\n",
    "        # Split data into training and validation sets\n",
    "        X_train, X_val = tr_embeddings_ND[train_idx], tr_embeddings_ND[val_idx]\n",
    "        y_train, y_val = y_train_df.values.ravel()[train_idx], y_train_df.values.ravel()[val_idx]\n",
    "        \n",
    "        # Train the model\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Get predictions for training and validation sets\n",
    "        y_train_pred_proba = knn.predict_proba(X_train)[:, 1]\n",
    "        y_val_pred_proba = knn.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Calculate AUROC for each fold\n",
    "        train_auroc = roc_auc_score(y_train, y_train_pred_proba)\n",
    "        val_auroc = roc_auc_score(y_val, y_val_pred_proba)\n",
    "        \n",
    "        train_auroc_per_fold.append(train_auroc)\n",
    "        val_auroc_per_fold.append(val_auroc)\n",
    "    \n",
    "    # Calculate the mean and standard deviation of AUROC scores across folds\n",
    "    train_auroc_means.append(np.mean(train_auroc_per_fold))\n",
    "    val_auroc_means.append(np.mean(val_auroc_per_fold))\n",
    "    train_auroc_std.append(np.std(train_auroc_per_fold))\n",
    "    val_auroc_std.append(np.std(val_auroc_per_fold))\n",
    "    \n",
    "    # Store the cross-validation score for selecting the best neighbors\n",
    "    yhat_cv_pred = cross_val_predict(knn, tr_embeddings_ND, y_train_df.values.ravel(),\n",
    "                                     cv=cv, method='predict_proba')\n",
    "    score = roc_auc_score(y_train_df, yhat_cv_pred[:, 1])  # Probability for class 1\n",
    "    results[i] = score\n",
    "\n",
    "# Find the best number of neighbors\n",
    "best_neighbors_idx = np.argmax(results)\n",
    "best_neighbors = neighbors[best_neighbors_idx]\n",
    "\n",
    "print(f\"Best AUROC score: {results[best_neighbors_idx]}\")\n",
    "print(f\"Optimal number of neighbors: {best_neighbors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP data:\n",
      "FP indices chosen: [0, 8, 17, 23, 24, 25, 26, 38, 40, 46]\n",
      "FP predictions and true sentiments [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]\n",
      "Sentences that were FP: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0dc98_row0_col0, #T_0dc98_row0_col1, #T_0dc98_row1_col0, #T_0dc98_row1_col1, #T_0dc98_row2_col0, #T_0dc98_row2_col1, #T_0dc98_row3_col0, #T_0dc98_row3_col1, #T_0dc98_row4_col0, #T_0dc98_row4_col1, #T_0dc98_row5_col0, #T_0dc98_row5_col1, #T_0dc98_row6_col0, #T_0dc98_row6_col1, #T_0dc98_row7_col0, #T_0dc98_row7_col1, #T_0dc98_row8_col0, #T_0dc98_row8_col1, #T_0dc98_row9_col0, #T_0dc98_row9_col1 {\n",
       "  text_align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0dc98\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0dc98_level0_col0\" class=\"col_heading level0 col0\" >website_name</th>\n",
       "      <th id=\"T_0dc98_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0dc98_row0_col0\" class=\"data row0 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row0_col1\" class=\"data row0 col1\" >Oh and I forgot to also mention the weird color effect it has on your phone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row1\" class=\"row_heading level0 row1\" >8</th>\n",
       "      <td id=\"T_0dc98_row1_col0\" class=\"data row1 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row1_col1\" class=\"data row1 col1\" >the only VERY DISAPPOINTING thing was there was NO SPEAKERPHONE!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row2\" class=\"row_heading level0 row2\" >17</th>\n",
       "      <td id=\"T_0dc98_row2_col0\" class=\"data row2 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row2_col1\" class=\"data row2 col1\" >I advise EVERYONE DO NOT BE FOOLED!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row3\" class=\"row_heading level0 row3\" >23</th>\n",
       "      <td id=\"T_0dc98_row3_col0\" class=\"data row3 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row3_col1\" class=\"data row3 col1\" >We have tried 2 units and they both failed within 2 months.. Pros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row4\" class=\"row_heading level0 row4\" >24</th>\n",
       "      <td id=\"T_0dc98_row4_col0\" class=\"data row4 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row4_col1\" class=\"data row4 col1\" >Also difficult to put on.I'd recommend avoiding this product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row5\" class=\"row_heading level0 row5\" >25</th>\n",
       "      <td id=\"T_0dc98_row5_col0\" class=\"data row5 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row5_col1\" class=\"data row5 col1\" >$50 Down the drain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row6\" class=\"row_heading level0 row6\" >26</th>\n",
       "      <td id=\"T_0dc98_row6_col0\" class=\"data row6 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row6_col1\" class=\"data row6 col1\" >Absolutel junk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row7\" class=\"row_heading level0 row7\" >38</th>\n",
       "      <td id=\"T_0dc98_row7_col0\" class=\"data row7 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row7_col1\" class=\"data row7 col1\" >[...] down the drain because of a weak snap!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row8\" class=\"row_heading level0 row8\" >40</th>\n",
       "      <td id=\"T_0dc98_row8_col0\" class=\"data row8 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row8_col1\" class=\"data row8 col1\" >Pretty piece of junk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0dc98_level0_row9\" class=\"row_heading level0 row9\" >46</th>\n",
       "      <td id=\"T_0dc98_row9_col0\" class=\"data row9 col0\" >amazon</td>\n",
       "      <td id=\"T_0dc98_row9_col1\" class=\"data row9 col1\" >If you are looking for a good quality Motorola Headset keep looking, this isn't it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2a6a555a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_neighbors, weights='distance')\n",
    "yhat_cv_pred = cross_val_predict(knn, tr_embeddings_ND, y_train_df.values.ravel(), \n",
    "                                     cv=cv, method='predict_proba')\n",
    "yhat_pred = list()\n",
    "for value in yhat_cv_pred[:, 1]:\n",
    "    if value < 0.5:\n",
    "        yhat_pred.append(0)\n",
    "    else:\n",
    "        yhat_pred.append(1)\n",
    "\n",
    "y_train_values = y_train_df.values.ravel()  # Flatten y_train_df to a 1D array if necessary\n",
    "yhat_pred = np.array(yhat_pred)\n",
    "\n",
    "_, fp, fn, _ = confusion_matrix(y_train_values, yhat_pred).ravel()\n",
    "FP = []\n",
    "FN = []\n",
    "\n",
    "\n",
    "for i, pred in enumerate(yhat_pred):\n",
    "    if pred == 1 and y_train_values[i] == 0:\n",
    "        FP.append(i)\n",
    "    if pred == 0 and y_train_values[i] == 1:\n",
    "        FN.append(i)\n",
    "\n",
    "# print(FP)\n",
    "\n",
    "# print(x_va.iloc[FP[0]])\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option(\"display.colheader_justify\",\"left\")\n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "\n",
    "va_idx_FP = FP[0:10]\n",
    "va_sent_predict_FP = yhat_pred[va_idx_FP]\n",
    "va_sent_true_FP = y_train_values[va_idx_FP]\n",
    "FP_styled_df = x_train_df.iloc[va_idx_FP].style.set_properties(**{'text_align': 'right'})\n",
    "\n",
    "print(\"FP data:\")\n",
    "print(\"FP indices chosen:\", va_idx_FP)\n",
    "print(\"FP predictions and true sentiments\", va_sent_predict_FP, va_sent_true_FP)\n",
    "print(\"Sentences that were FP: \\n\")\n",
    "FP_styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN data:\n",
      "FN indices chosen: [412, 430, 435, 444, 453, 455, 458, 461, 482, 487]\n",
      "FN predictions and true sentiments [0 0 0 0 0 0 0 0 0 0] [1 1 1 1 1 1 1 1 1 1]\n",
      "Sentences that were FN: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e6814_row0_col0, #T_e6814_row0_col1, #T_e6814_row1_col0, #T_e6814_row1_col1, #T_e6814_row2_col0, #T_e6814_row2_col1, #T_e6814_row3_col0, #T_e6814_row3_col1, #T_e6814_row4_col0, #T_e6814_row4_col1, #T_e6814_row5_col0, #T_e6814_row5_col1, #T_e6814_row6_col0, #T_e6814_row6_col1, #T_e6814_row7_col0, #T_e6814_row7_col1, #T_e6814_row8_col0, #T_e6814_row8_col1, #T_e6814_row9_col0, #T_e6814_row9_col1 {\n",
       "  text_align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e6814\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e6814_level0_col0\" class=\"col_heading level0 col0\" >website_name</th>\n",
       "      <th id=\"T_e6814_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row0\" class=\"row_heading level0 row0\" >412</th>\n",
       "      <td id=\"T_e6814_row0_col0\" class=\"data row0 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row0_col1\" class=\"data row0 col1\" >Plan on ordering from them again and again.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row1\" class=\"row_heading level0 row1\" >430</th>\n",
       "      <td id=\"T_e6814_row1_col0\" class=\"data row1 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row1_col1\" class=\"data row1 col1\" >I have to use the smallest earpieces provided, but it stays on pretty well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row2\" class=\"row_heading level0 row2\" >435</th>\n",
       "      <td id=\"T_e6814_row2_col0\" class=\"data row2 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row2_col1\" class=\"data row2 col1\" >This is cool because most cases are just open there allowing the screen to get all scratched up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row3\" class=\"row_heading level0 row3\" >444</th>\n",
       "      <td id=\"T_e6814_row3_col0\" class=\"data row3 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row3_col1\" class=\"data row3 col1\" >I was amazed at the quick arrival of the two original lg cell phone batteries and and at a fraction of the price.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row4\" class=\"row_heading level0 row4\" >453</th>\n",
       "      <td id=\"T_e6814_row4_col0\" class=\"data row4 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row4_col1\" class=\"data row4 col1\" >Overall, I would recommend this phone over the new Walkman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row5\" class=\"row_heading level0 row5\" >455</th>\n",
       "      <td id=\"T_e6814_row5_col0\" class=\"data row5 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row5_col1\" class=\"data row5 col1\" >I ended up sliding it on the edge of my pants or back pockets instead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row6\" class=\"row_heading level0 row6\" >458</th>\n",
       "      <td id=\"T_e6814_row6_col0\" class=\"data row6 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row6_col1\" class=\"data row6 col1\" >I had to go to a store and bought a new NOKIA phone which is working great.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row7\" class=\"row_heading level0 row7\" >461</th>\n",
       "      <td id=\"T_e6814_row7_col0\" class=\"data row7 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row7_col1\" class=\"data row7 col1\" >It seems completely secure, both holding on to my belt, and keeping the iPhone inside.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row8\" class=\"row_heading level0 row8\" >482</th>\n",
       "      <td id=\"T_e6814_row8_col0\" class=\"data row8 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row8_col1\" class=\"data row8 col1\" >This is hands down the best phone I've ever had.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e6814_level0_row9\" class=\"row_heading level0 row9\" >487</th>\n",
       "      <td id=\"T_e6814_row9_col0\" class=\"data row9 col0\" >amazon</td>\n",
       "      <td id=\"T_e6814_row9_col1\" class=\"data row9 col1\" >It definitely was not as good as my S11.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x299a913f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_idx_FN = FN[0:10]\n",
    "va_sent_predict_FN = yhat_pred[va_idx_FN]\n",
    "va_sent_true_FN = y_train_values[va_idx_FN]\n",
    "FN_styled_df = x_train_df.iloc[va_idx_FN].style.set_properties(**{'text_align': 'right'})\n",
    "\n",
    "print(\"FN data:\")\n",
    "print(\"FN indices chosen:\", va_idx_FN)\n",
    "print(\"FN predictions and true sentiments\", va_sent_predict_FN, va_sent_true_FN)\n",
    "print(\"Sentences that were FN: \\n\")\n",
    "FN_styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 86 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# choose some query sentences\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# use K-nearest neighbors to find the 5 reviews that most closely resemble the query review\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# for test_id in range(len(x_train)):\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     query_QF = tr_embeddings_ND[test_id][np.newaxis, :]\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m knn \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(\u001b[43mneighbors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbest_neighbors\u001b[49m\u001b[43m]\u001b[49m, weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m knn\u001b[38;5;241m.\u001b[39mfit(tr_embeddings_ND, y_train_df\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel())\n\u001b[1;32m      9\u001b[0m yhat \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict_proba(te_embeddings_ND)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 86 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "# choose some query sentences\n",
    "\n",
    "# use K-nearest neighbors to find the 5 reviews that most closely resemble the query review\n",
    "# for test_id in range(len(x_train)):\n",
    "#     query_QF = tr_embeddings_ND[test_id][np.newaxis, :]\n",
    "knn = KNeighborsClassifier(best_neighbors, weights='distance')\n",
    "knn.fit(tr_embeddings_ND, y_train_df.values.ravel())\n",
    "\n",
    "yhat = knn.predict_proba(te_embeddings_ND)\n",
    "\n",
    "file = open(\"yproba1_test.txt\", \"w+\")\n",
    "for value in yhat[:, 1]:\n",
    "    line = str(value) + \"\\n\"\n",
    "    file.write(line)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
