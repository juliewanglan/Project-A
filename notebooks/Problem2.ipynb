{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juliewang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # copied over from ipynb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # tried to use this vocab but ended up with lower accuracy than the built in stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "SEED = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "#This sets the default style for all figures. \n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train_df: (2400, 2)\n",
      "Shape of y_train_df: (2400, 1)\n",
      "row     0 | y = 0 | Oh and I forgot to also mention the weird color effect it has on your phone.\n",
      "row     1 | y = 0 | THAT one didn't work either.\n",
      "row     2 | y = 0 | Waste of 13 bucks.\n",
      "row     3 | y = 0 | Product is useless, since it does not have enough charging current to charge the 2 cellphones I was planning to use it with.\n",
      "row     4 | y = 0 | None of the three sizes they sent with the headset would stay in my ears.\n",
      "...\n",
      "row  2395 | y = 1 | The sweet potato fries were very good and seasoned well.\n",
      "row  2396 | y = 1 | I could eat their bruschetta all day it is devine.\n",
      "row  2397 | y = 1 | Ambience is perfect.\n",
      "row  2398 | y = 1 | We ordered the duck rare and it was pink and tender on the inside with a nice char on the outside.\n",
      "row  2399 | y = 1 | Service was good and the company was better!\n"
     ]
    }
   ],
   "source": [
    "# load the csv files\n",
    "if __name__ == '__main__':\n",
    "    data_dir = '../data_reviews'\n",
    "    x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "    y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "    N, n_cols = x_train_df.shape\n",
    "    print(\"Shape of x_train_df: (%d, %d)\" % (N,n_cols))\n",
    "    print(\"Shape of y_train_df: %s\" % str(y_train_df.shape))\n",
    "\n",
    "    # Print out the first five rows and last five rows\n",
    "    tr_text_list = x_train_df['text'].values.tolist()\n",
    "    rows = np.arange(0, 5)\n",
    "    for row_id in rows:\n",
    "        text = tr_text_list[row_id]\n",
    "        print(\"row %5d | y = %d | %s\" % (row_id, y_train_df.values[row_id,0], text))\n",
    "\n",
    "    print(\"...\")\n",
    "    rows = np.arange(N - 5, N)\n",
    "    for row_id in rows:\n",
    "        text = tr_text_list[row_id]\n",
    "        print(\"row %5d | y = %d | %s\" % (row_id, y_train_df.values[row_id,0], text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up training data into training set and validation set\n",
    "x_train, x_va, y_train, y_va = train_test_split(x_train_df, y_train_df, test_size=0.2, random_state=SEED)\n",
    "y_train = y_train.values.ravel()\n",
    "y_va = y_va.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define logistic regression pipeline function\n",
    "def make_rfc_pipeline():\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "         ('vectorizer', TfidfVectorizer(\n",
    "             lowercase=True, # make the text uniformly lowercase\n",
    "             stop_words='english', # remove filler words ('a', 'the', etc.) present in the stopwords nltk library\n",
    "             analyzer='word', # breakdown text into words for feature analysis\n",
    "             min_df = 0.05, \n",
    "             max_df=0.70, # ignore words with a frequency strictly higher than 50%\n",
    "             token_pattern=r'\\b\\w+\\b', # removes punctuation and numbers\n",
    "             ngram_range=(1,2) # extracts unigrams and bigrams\n",
    "             )\n",
    "            ),\n",
    "         ('knn', KNeighborsClassifier()),\n",
    "        ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pipeline\n",
    "pipe = make_rfc_pipeline()\n",
    "\n",
    "# make hyperparameter C grid (regularization strength), 20 logspaced values from 10e-6 to 10e6\n",
    "N_grid = np.linspace(1, 20, 2, dtype=int)\n",
    "param_grid = {'knn__n_neighbors': N_grid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.553125\n",
      "Validation Accuracy: 0.5520833333333334\n",
      "Best C: {'knn__n_neighbors': 20}\n"
     ]
    }
   ],
   "source": [
    "# make hyperparameter C grid (regularization strength), 20 logspaced values from 10e-6 to 10e6\n",
    "# n_estimators_grid = np.logspace(-6, 6, 20)\n",
    "# param_grid = {'rfc__C': C_grid}\n",
    "\n",
    "# perform grid search and fit the model\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, # estimator\n",
    "    param_grid=param_grid, # hyperparameter C\n",
    "    cv=5, # 5-fold cross validation\n",
    "    scoring='roc_auc' # calculates AUROC to compare the hyperparameter(s)\n",
    ")\n",
    "\n",
    "grid_search.fit(x_train['text'], y_train)\n",
    "grid_predictions_va = grid_search.predict(x_va['text'])\n",
    "grid_predictions_tr = grid_search.predict(x_train['text'])\n",
    "\n",
    "# calculate and print accuracy for training and validation datasets\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, grid_predictions_tr))\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_va, grid_predictions_va))\n",
    "\n",
    "# best parameter found in the grid search\n",
    "print(\"Best C:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP data:\n",
      "FP indices chosen: [4, 6, 7, 11, 12, 13, 14, 19, 22, 25]\n",
      "FP predictions and true sentiments [1 1 1 1 1 1 1 1 1 1] [0 0 0 0 0 0 0 0 0 0]\n",
      "Sentences that were FP: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f83f7_row0_col0, #T_f83f7_row0_col1, #T_f83f7_row1_col0, #T_f83f7_row1_col1, #T_f83f7_row2_col0, #T_f83f7_row2_col1, #T_f83f7_row3_col0, #T_f83f7_row3_col1, #T_f83f7_row4_col0, #T_f83f7_row4_col1, #T_f83f7_row5_col0, #T_f83f7_row5_col1, #T_f83f7_row6_col0, #T_f83f7_row6_col1, #T_f83f7_row7_col0, #T_f83f7_row7_col1, #T_f83f7_row8_col0, #T_f83f7_row8_col1, #T_f83f7_row9_col0, #T_f83f7_row9_col1 {\n",
       "  text_align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f83f7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f83f7_level0_col0\" class=\"col_heading level0 col0\" >website_name</th>\n",
       "      <th id=\"T_f83f7_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row0\" class=\"row_heading level0 row0\" >1907</th>\n",
       "      <td id=\"T_f83f7_row0_col0\" class=\"data row0 col0\" >yelp</td>\n",
       "      <td id=\"T_f83f7_row0_col1\" class=\"data row0 col1\" >for 40 bucks a head, i really expect better food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row1\" class=\"row_heading level0 row1\" >300</th>\n",
       "      <td id=\"T_f83f7_row1_col0\" class=\"data row1 col0\" >amazon</td>\n",
       "      <td id=\"T_f83f7_row1_col1\" class=\"data row1 col1\" >worthless product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row2\" class=\"row_heading level0 row2\" >1964</th>\n",
       "      <td id=\"T_f83f7_row2_col0\" class=\"data row2 col0\" >yelp</td>\n",
       "      <td id=\"T_f83f7_row2_col1\" class=\"data row2 col1\" >I also decided not to send it back because our waitress looked like she was on the verge of having a heart attack.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row3\" class=\"row_heading level0 row3\" >1659</th>\n",
       "      <td id=\"T_f83f7_row3_col0\" class=\"data row3 col0\" >yelp</td>\n",
       "      <td id=\"T_f83f7_row3_col1\" class=\"data row3 col1\" >I've never been treated so bad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row4\" class=\"row_heading level0 row4\" >1663</th>\n",
       "      <td id=\"T_f83f7_row4_col0\" class=\"data row4 col0\" >yelp</td>\n",
       "      <td id=\"T_f83f7_row4_col1\" class=\"data row4 col1\" >The burger had absolutely no flavor - the meat itself was totally bland, the burger was overcooked and there was no charcoal flavor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row5\" class=\"row_heading level0 row5\" >1743</th>\n",
       "      <td id=\"T_f83f7_row5_col0\" class=\"data row5 col0\" >yelp</td>\n",
       "      <td id=\"T_f83f7_row5_col1\" class=\"data row5 col1\" >I was disgusted because I was pretty sure that was human hair.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row6\" class=\"row_heading level0 row6\" >1991</th>\n",
       "      <td id=\"T_f83f7_row6_col0\" class=\"data row6 col0\" >yelp</td>\n",
       "      <td id=\"T_f83f7_row6_col1\" class=\"data row6 col1\" >I think this restaurant suffers from not trying hard enough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row7\" class=\"row_heading level0 row7\" >374</th>\n",
       "      <td id=\"T_f83f7_row7_col0\" class=\"data row7 col0\" >amazon</td>\n",
       "      <td id=\"T_f83f7_row7_col1\" class=\"data row7 col1\" >My only complaint is the standard sound volume is a little low even when turned up to 5(of 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row8\" class=\"row_heading level0 row8\" >1946</th>\n",
       "      <td id=\"T_f83f7_row8_col0\" class=\"data row8 col0\" >yelp</td>\n",
       "      <td id=\"T_f83f7_row8_col1\" class=\"data row8 col1\" >The bus boy on the other hand was so rude.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f83f7_level0_row9\" class=\"row_heading level0 row9\" >1766</th>\n",
       "      <td id=\"T_f83f7_row9_col0\" class=\"data row9 col0\" >yelp</td>\n",
       "      <td id=\"T_f83f7_row9_col1\" class=\"data row9 col1\" >A lady at the table next to us found a live green caterpillar In her salad.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16262c160>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, fp, fn, _ = confusion_matrix(y_va, grid_predictions_va).ravel()\n",
    "FP = []\n",
    "FN = []\n",
    "\n",
    "for i, pred in enumerate(grid_predictions_va):\n",
    "    if pred == 1 and y_va[i] == 0:\n",
    "        FP.append(i)\n",
    "    if pred == 0 and y_va[i] == 1:\n",
    "        FN.append(i)\n",
    "\n",
    "# print(FP)\n",
    "\n",
    "# print(x_va.iloc[FP[0]])\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option(\"display.colheader_justify\",\"left\")\n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "\n",
    "va_idx_FP = FP[0:10]\n",
    "va_sent_predict_FP = grid_predictions_va[va_idx_FP]\n",
    "va_sent_true_FP = y_va[va_idx_FP]\n",
    "FP_styled_df = x_va.iloc[va_idx_FP].style.set_properties(**{'text_align': 'right'})\n",
    "\n",
    "print(\"FP data:\")\n",
    "print(\"FP indices chosen:\", va_idx_FP)\n",
    "print(\"FP predictions and true sentiments\", va_sent_predict_FP, va_sent_true_FP)\n",
    "print(\"Sentences that were FP: \\n\")\n",
    "FP_styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN data:\n",
      "FN indices chosen: [16, 24, 58, 67, 69, 95, 102, 122, 124, 132]\n",
      "FN predictions and true sentiments [0 0 0 0 0 0 0 0 0 0] [1 1 1 1 1 1 1 1 1 1]\n",
      "Sentences that were FN: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4d470_row0_col0, #T_4d470_row0_col1, #T_4d470_row1_col0, #T_4d470_row1_col1, #T_4d470_row2_col0, #T_4d470_row2_col1, #T_4d470_row3_col0, #T_4d470_row3_col1, #T_4d470_row4_col0, #T_4d470_row4_col1, #T_4d470_row5_col0, #T_4d470_row5_col1, #T_4d470_row6_col0, #T_4d470_row6_col1, #T_4d470_row7_col0, #T_4d470_row7_col1, #T_4d470_row8_col0, #T_4d470_row8_col1, #T_4d470_row9_col0, #T_4d470_row9_col1 {\n",
       "  text_align: right;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4d470\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4d470_level0_col0\" class=\"col_heading level0 col0\" >website_name</th>\n",
       "      <th id=\"T_4d470_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row0\" class=\"row_heading level0 row0\" >606</th>\n",
       "      <td id=\"T_4d470_row0_col0\" class=\"data row0 col0\" >amazon</td>\n",
       "      <td id=\"T_4d470_row0_col1\" class=\"data row0 col1\" >Restored my phone to like new performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row1\" class=\"row_heading level0 row1\" >1313</th>\n",
       "      <td id=\"T_4d470_row1_col0\" class=\"data row1 col0\" >imdb</td>\n",
       "      <td id=\"T_4d470_row1_col1\" class=\"data row1 col1\" >Thanks good a movie like this was done and released.  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row2\" class=\"row_heading level0 row2\" >511</th>\n",
       "      <td id=\"T_4d470_row2_col0\" class=\"data row2 col0\" >amazon</td>\n",
       "      <td id=\"T_4d470_row2_col1\" class=\"data row2 col1\" >I have used several phone in two years, but this one is the best.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row3\" class=\"row_heading level0 row3\" >2374</th>\n",
       "      <td id=\"T_4d470_row3_col0\" class=\"data row3 col0\" >yelp</td>\n",
       "      <td id=\"T_4d470_row3_col1\" class=\"data row3 col1\" >The goat taco didn't skimp on the meat and wow what FLAVOR!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row4\" class=\"row_heading level0 row4\" >1563</th>\n",
       "      <td id=\"T_4d470_row4_col0\" class=\"data row4 col0\" >imdb</td>\n",
       "      <td id=\"T_4d470_row4_col1\" class=\"data row4 col1\" >I don't think you will be disappointed.  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row5\" class=\"row_heading level0 row5\" >1215</th>\n",
       "      <td id=\"T_4d470_row5_col0\" class=\"data row5 col0\" >imdb</td>\n",
       "      <td id=\"T_4d470_row5_col1\" class=\"data row5 col1\" >I rate this movie 9/10.  </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row6\" class=\"row_heading level0 row6\" >544</th>\n",
       "      <td id=\"T_4d470_row6_col0\" class=\"data row6 col0\" >amazon</td>\n",
       "      <td id=\"T_4d470_row6_col1\" class=\"data row6 col1\" >Phone is sturdy as all nokia bar phones are.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row7\" class=\"row_heading level0 row7\" >502</th>\n",
       "      <td id=\"T_4d470_row7_col0\" class=\"data row7 col0\" >amazon</td>\n",
       "      <td id=\"T_4d470_row7_col1\" class=\"data row7 col1\" >I love this phone , It is very handy and has a lot of features .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row8\" class=\"row_heading level0 row8\" >483</th>\n",
       "      <td id=\"T_4d470_row8_col0\" class=\"data row8 col0\" >amazon</td>\n",
       "      <td id=\"T_4d470_row8_col1\" class=\"data row8 col1\" >This BlueAnt Supertooth hands-free phone speaker is AWESOME.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4d470_level0_row9\" class=\"row_heading level0 row9\" >1477</th>\n",
       "      <td id=\"T_4d470_row9_col0\" class=\"data row9 col0\" >imdb</td>\n",
       "      <td id=\"T_4d470_row9_col1\" class=\"data row9 col1\" >I won't spoil it, but the ending in pretty amazing.  </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x162ee04f0>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "va_idx_FN = FN[0:10]\n",
    "va_sent_predict_FN = grid_predictions_va[va_idx_FN]\n",
    "va_sent_true_FN = y_va[va_idx_FN]\n",
    "FN_styled_df = x_va.iloc[va_idx_FN].style.set_properties(**{'text_align': 'right'})\n",
    "\n",
    "print(\"FN data:\")\n",
    "print(\"FN indices chosen:\", va_idx_FN)\n",
    "print(\"FN predictions and true sentiments\", va_sent_predict_FN, va_sent_true_FN)\n",
    "print(\"Sentences that were FN: \\n\")\n",
    "FN_styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'log_regr__C'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print best parameter and best score\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest C: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_regr__C\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest AUROC score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_score_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# plot the performance of different regularization strengths\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log_regr__C'"
     ]
    }
   ],
   "source": [
    " # print best parameter and best score\n",
    "print(f'Best C: {grid_search.best_params_[\"log_regr__C\"]}')\n",
    "print(f'Best AUROC score: {grid_search.best_score_}')\n",
    "\n",
    "# plot the performance of different regularization strengths\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(N_grid, scores, marker='o')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('C (Inverse Regularization Strength)')\n",
    "ax.set_ylabel('Mean AUROC')\n",
    "ax.set_title('Effect of C on AUROC (5-fold CV)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peak of the graph indicates the best C value - this will prevent over- and under-fitting to the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 1 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0\n",
      " 1 0 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "x_test = pd.read_csv(os.path.join(data_dir, 'x_test.csv'))\n",
    "grid_predictions_test = grid_search.predict(x_test['text'])\n",
    "grid_predictions_test_T = np.transpose(grid_predictions_test)\n",
    "print(str(grid_predictions_test_T))\n",
    "\n",
    "file = open(\"yproba1_test.txt\", \"w+\")\n",
    "for value in grid_predictions_test:\n",
    "    line = str(value) + \"\\n\"\n",
    "    file.write(line)\n",
    "file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
